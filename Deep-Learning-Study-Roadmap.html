<!DOCTYPE html>
<html lang="en">
    <!-- title -->




<!-- keywords -->




<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" >
    <meta name="author" content="Changyu Li">
    <meta name="renderer" content="webkit">
    <meta name="copyright" content="Changyu Li">
    
    <meta name="keywords" content="hexo,hexo-theme,hexo-blog">
    
    <meta name="description" content="">
    <meta http-equiv="Cache-control" content="no-cache">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    <title>Deep Learning Study Roadmap · FizzerYu&#39;s Blog</title>
    <style type="text/css">
    @font-face {
        font-family: 'Oswald-Regular';
        src: url("/font/Oswald-Regular.ttf");
    }

    body {
        margin: 0;
    }

    header,
    footer,
    .back-top,
    .sidebar,
    .container,
    .site-intro-meta,
    .toc-wrapper {
        display: none;
    }

    .site-intro {
        position: relative;
        z-index: 3;
        width: 100%;
        /* height: 50vh; */
        overflow: hidden;
    }

    .site-intro-placeholder {
        position: absolute;
        z-index: -2;
        top: 0;
        left: 0;
        width: calc(100% + 300px);
        height: 100%;
        background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
        background-position: center center;
        transform: translate3d(-226px, 0, 0);
        animation: gradient-move 2.5s ease-out 0s infinite;
    }

    @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }

</style>

    <link rel="preload" href= "/css/style.css?v=20180824" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    <link rel="stylesheet" href= "/css/mobile.css?v=20180824" media="(max-width: 980px)">
    
    <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    
    <!-- /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/ -->
<script>
(function( w ){
	"use strict";
	// rel=preload support test
	if( !w.loadCSS ){
		w.loadCSS = function(){};
	}
	// define on the loadCSS obj
	var rp = loadCSS.relpreload = {};
	// rel=preload feature support test
	// runs once and returns a function for compat purposes
	rp.support = (function(){
		var ret;
		try {
			ret = w.document.createElement( "link" ).relList.supports( "preload" );
		} catch (e) {
			ret = false;
		}
		return function(){
			return ret;
		};
	})();

	// if preload isn't supported, get an asynchronous load by using a non-matching media attribute
	// then change that media back to its intended value on load
	rp.bindMediaToggle = function( link ){
		// remember existing media attr for ultimate state, or default to 'all'
		var finalMedia = link.media || "all";

		function enableStylesheet(){
			link.media = finalMedia;
		}

		// bind load handlers to enable media
		if( link.addEventListener ){
			link.addEventListener( "load", enableStylesheet );
		} else if( link.attachEvent ){
			link.attachEvent( "onload", enableStylesheet );
		}

		// Set rel and non-applicable media type to start an async request
		// note: timeout allows this to happen async to let rendering continue in IE
		setTimeout(function(){
			link.rel = "stylesheet";
			link.media = "only x";
		});
		// also enable media after 3 seconds,
		// which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
		setTimeout( enableStylesheet, 3000 );
	};

	// loop through link elements in DOM
	rp.poly = function(){
		// double check this to prevent external calls from running
		if( rp.support() ){
			return;
		}
		var links = w.document.getElementsByTagName( "link" );
		for( var i = 0; i < links.length; i++ ){
			var link = links[ i ];
			// qualify links to those with rel=preload and as=style attrs
			if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
				// prevent rerunning on link
				link.setAttribute( "data-loadcss", true );
				// bind listeners to toggle media back
				rp.bindMediaToggle( link );
			}
		}
	};

	// if unsupported, run the polyfill
	if( !rp.support() ){
		// run once at least
		rp.poly();

		// rerun poly on an interval until onload
		var run = w.setInterval( rp.poly, 500 );
		if( w.addEventListener ){
			w.addEventListener( "load", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		} else if( w.attachEvent ){
			w.attachEvent( "onload", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		}
	}


	// commonjs
	if( typeof exports !== "undefined" ){
		exports.loadCSS = loadCSS;
	}
	else {
		w.loadCSS = loadCSS;
	}
}( typeof global !== "undefined" ? global : this ) );
</script>

    <link rel="icon" href= "/avatar/mypic.jpg" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js" as="script" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" as="script" />
    <link rel="preload" href="/scripts/main.js" as="script" />
    <link rel="preload" as="font" href="/font/Oswald-Regular.ttf" crossorigin>
    <link rel="preload" as="font" href="https://at.alicdn.com/t/font_327081_1dta1rlogw17zaor.woff" crossorigin>
    
    <!-- fancybox -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script>
    <!-- 百度统计  -->
    
    <script>
        var _hmt = _hmt || [];
        (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?https://hm.baidu.com/hm.js?4b66631576b78a23d81b5bad405cd438";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
        })();
    </script>
    
    <!-- 谷歌统计  -->
    
<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

    
        <body class="post-body">
    
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/" >FizzerYu&#39;s Blog</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">Deep Learning Study Roadmap</a>
            </div>
    </div>
    
    <a class="home-link" href=/>FizzerYu's Blog</a>
</header>
    <div class="wrapper">
        <div class="site-intro" style="







height:50vh;
">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-img" style="background-image: url(/intro/deeplearning.png)"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            Deep Learning Study Roadmap
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <div class="post-intros">
                <!-- 文章页标签  -->
                
                    <div class= post-intro-tags >
    
        <a class="post-tag" href="javascript:void(0);" data-tags = "Deep Learning">Deep Learning</a>
    
        <a class="post-tag" href="javascript:void(0);" data-tags = "论文阅读">论文阅读</a>
    
</div>
                
                
                    <div class="post-intro-read">
                        <span>Word count: <span class="post-count word-count">3.3k</span>Reading time: <span class="post-count reading-time">13 min</span></span>
                    </div>
                
                <div class="post-intro-meta">
                    <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                    <span class="post-intro-time">2020/02/01</span>
                    
                    <span id="busuanzi_container_page_pv" class="busuanzi-pv">
                        <span class="iconfont-archer">&#xe602;</span>
                        <span id="busuanzi_value_page_pv"></span>
                    </span>
                    
                    <span class="shareWrapper">
                        <span class="iconfont-archer shareIcon">&#xe71d;</span>
                        <span class="shareText">Share</span>
                        <ul class="shareList">
                            <li class="iconfont-archer share-qr" data-type="qr">&#xe75b;
                                <div class="share-qrcode"></div>
                            </li>
                            <li class="iconfont-archer" data-type="weibo">&#xe619;</li>
                            <li class="iconfont-archer" data-type="qzone">&#xe62e;</li>
                            <li class="iconfont-archer" data-type="twitter">&#xe634;</li>
                            <li class="iconfont-archer" data-type="facebook">&#xe67a;</li>
                        </ul>
                    </span>
                </div>
            </div>
        
    </div>
</div>
        <script>
 
  // get user agent
  var browser = {
    versions: function () {
      var u = window.navigator.userAgent;
      return {
        userAgent: u,
        trident: u.indexOf('Trident') > -1, //IE内核
        presto: u.indexOf('Presto') > -1, //opera内核
        webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
        gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
        mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
        ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
        android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
        iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
        iPad: u.indexOf('iPad') > -1, //是否为iPad
        webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
        weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
        uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
      };
    }()
  }
  console.log("userAgent:" + browser.versions.userAgent);

  // callback
  function fontLoaded() {
    console.log('font loaded');
    if (document.getElementsByClassName('site-intro-meta')) {
      document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
      document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
      var postIntros = document.getElementsByClassName('post-intros')[0]
      if (postIntros) {
        postIntros.classList.add('post-fade-in');
      }
    }
  }

  // UC不支持跨域，所以直接显示
  function asyncCb(){
    if (browser.versions.uc) {
      console.log("UCBrowser");
      fontLoaded();
    } else {
      WebFont.load({
        custom: {
          families: ['Oswald-Regular']
        },
        loading: function () {  //所有字体开始加载
          // console.log('loading');
        },
        active: function () {  //所有字体已渲染
          fontLoaded();
        },
        inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
          console.log('inactive: timeout');
          fontLoaded();
        },
        timeout: 5000 // Set the timeout to two seconds
      });
    }
  }

  function asyncErr(){
    console.warn('script load from CDN failed, will load local script')
  }

  // load webfont-loader async, and add callback function
  function async(u, cb, err) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (cb) { o.addEventListener('load', function (e) { cb(null, e); }, false); }
    if (err) { o.addEventListener('error', function (e) { err(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }

  var asyncLoadWithFallBack = function(arr, success, reject) {
      var currReject = function(){
        reject()
        arr.shift()
        if(arr.length)
          async(arr[0], success, currReject)
        }

      async(arr[0], success, currReject)
  }

  asyncLoadWithFallBack([
    "https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js", 
    "https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js",
    "/lib/webfontloader.min.js"
  ], asyncCb, asyncErr)
</script>        
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <h2 id="1-Deep-Learning-Report"><a href="#1-Deep-Learning-Report" class="headerlink" title="1 Deep Learning Report"></a>1 Deep Learning Report</h2><blockquote>
<p>Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. “A fast learning algorithm for deep belief nets.” Neural computation 18.7 (2006): 1527-1554.<br><a href="http://www.cs.toronto.edu/%7Ehinton/absps/ncfast.pdf" target="_blank" rel="noopener">http://www.cs.toronto.edu/%7Ehinton/absps/ncfast.pdf</a><br><a href="https://www.nature.com/articles/nature14539" target="_blank" rel="noopener">https://www.nature.com/articles/nature14539</a></p>
</blockquote>
<ul>
<li>Conventional machine-learning techniques were limited in their ability to process natural data in their raw form. </li>
<li>Representation learning is a set of methods that allows a machine to be fed with raw data and to automatically discover the representations needed for detection or classification. </li>
<li><a href="https://blog.csdn.net/weixin_38347387/article/details/82936585" target="_blank" rel="noopener">关于理解反向传播的一篇文章</a>  </li>
<li>为什么要使用激活函数—》不使用激活函数的神经网络都是<strong>线性模型</strong>，只是输入线性组合的再输出。关于为何使用ReLU激活函数，文中的理由为“ReLU typically <strong>learns much faster</strong> in networks with many layers, allowing training of a deep supervised network without unsupervised pre-training”【Reference: Glorot, X., Bordes, A. &amp; Bengio. Y. Deep sparse rectifier neural networks. In Proc. 14th International Conference on Artificial Intelligence and Statistics 315–323 (2011). This paper showed that supervised training of very deep neural networks is much faster if the hidden layers are composed of ReLU.】<ul>
<li>但是明显还有更深层次的原因：<ul>
<li><a href="https://www.cnblogs.com/itmorn/p/11132494.html" target="_blank" rel="noopener">激活函数的理解1</a>        </li>
<li><a href="https://www.cnblogs.com/missidiot/p/9378079.html" target="_blank" rel="noopener">激活函数的理解2</a>       </li>
</ul>
</li>
</ul>
</li>
<li>这里有个问题：CNN中的反向传播是如何进行的  <a href="https://blog.csdn.net/qq_16137569/article/details/81477906" target="_blank" rel="noopener">https://blog.csdn.net/qq_16137569/article/details/81477906</a></li>
<li>Distributed representations and language processing 没太看懂，貌似是说词向量的问题</li>
<li>为何LSTM比单纯的RNN在序列信息的处理上效果更好: RNN “Although their main purpose is to learn long-term dependencies, theoretical and empirical evidence shows that it is difficult to learn to store information for very long”【Bengio, Y., Simard, P. &amp; Frasconi, P. Learning long-term dependencies with gradient descent is difficult. IEEE Trans. Neural Networks 5, 157–166 (1994).】 —“To correct for that, one idea is to augment the network with an explicit memory. ”—》LSTM</li>
<li>最后作者提到的是<strong>期待无监督学习替代监督学习</strong>，毕竟人自身就是这么成长的，但是个人感觉这需要非常大量的数据作为支撑，可能需要十几年的数据量，而且不只是视频数据。</li>
</ul>
<h2 id="2-DBN"><a href="#2-DBN" class="headerlink" title="2 DBN"></a>2 DBN</h2><h3 id="2-1-深度学习前夜的里程碑"><a href="#2-1-深度学习前夜的里程碑" class="headerlink" title="2.1 深度学习前夜的里程碑"></a>2.1 深度学习前夜的里程碑</h3><blockquote>
<p>Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. “A fast learning algorithm for deep belief nets.” Neural computation 18.7 (2006): 1527-1554.<br><a href="http://www.cs.toronto.edu/%7Ehinton/absps/ncfast.pdf" target="_blank" rel="noopener">http://www.cs.toronto.edu/%7Ehinton/absps/ncfast.pdf</a></p>
</blockquote>
<ul>
<li><img src="https://img-blog.csdn.net/20161213124220124?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYTgxOTgyNTI5NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="网络结构"></li>
<li>非常难得文章，还只是初步了解（20%）</li>
<li>reference：<ul>
<li><a href="笔记https://zhuanlan.zhihu.com/p/48191799">《A fast learning algorithm for deep belief nets》</a></li>
<li><a href="https://blog.csdn.net/a819825294/article/details/53608141" target="_blank" rel="noopener">深度信念网络（DBN）</a></li>
<li><a href="https://space.bilibili.com/97068901" target="_blank" rel="noopener">B站简介</a></li>
</ul>
</li>
</ul>
<h3 id="2-2-展示深度学习前景的里程碑"><a href="#2-2-展示深度学习前景的里程碑" class="headerlink" title="2.2 展示深度学习前景的里程碑"></a>2.2 展示深度学习前景的里程碑</h3><blockquote>
<p>Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. “Reducing the dimensionality of data with neural networks.” Science 313.5786 (2006): 504-507.<br><a href="http://www.cs.toronto.edu/%7Ehinton/science.pdf" target="_blank" rel="noopener">http://www.cs.toronto.edu/%7Ehinton/science.pdf</a></p>
</blockquote>
<ul>
<li>We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.</li>
<li><a href="https://cloud.tencent.com/developer/article/1157274" target="_blank" rel="noopener">中文译文</a></li>
<li>看了一下 这两篇论文都是关于DBN的，这一篇在前说的是训练，上一篇在后，引出了DBN</li>
</ul>
<h2 id="3-ImageNet革命（深度学习大爆炸）"><a href="#3-ImageNet革命（深度学习大爆炸）" class="headerlink" title="3 ImageNet革命（深度学习大爆炸）"></a>3 ImageNet革命（深度学习大爆炸）</h2><h3 id="3-1-AlexNet的深度学习突破"><a href="#3-1-AlexNet的深度学习突破" class="headerlink" title="3.1 AlexNet的深度学习突破"></a>3.1 AlexNet的深度学习突破</h3><blockquote>
<p>Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. “Imagenet classification with deep convolutional neural networks.” Advances in neural information processing systems. 2012.<br><a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a></p>
</blockquote>
<ul>
<li><a href="https://blog.csdn.net/HelloZEX/article/details/80624083" target="_blank" rel="noopener">论文的中文翻译版本</a></li>
<li>网络结构：<ul>
<li><img src="https://d3i71xaburhd42.cloudfront.net/d98c78216668ca95f01bc892647a6242ec43f719/4-Figure2-1.png" alt="网络结构"></li>
<li>图上input层图片的尺寸有问题，应该是227x227x3，而不是224x224x3（这个问题貌似无解，有些人说是AlexNet图片预处理之后变成227x227x3的）。因为使用96个kernels（96,11,11,3），stride = 4，（[227-11] / 4 + 1 ）= 55；（[224-11] / 4 + 1 ）= 54.25</li>
<li>受限于当时的GPU，AlexNet是分布在两个GPU（GTX 580 3GB GPUs）上进行训练的。这两个GPU之间进行有限的通讯。关于GPU之间的通信，比如说input层后的第一层第二层之间的虚线是分开的，说明没有通信，即第二层上面的128map是由第一层上面的48map计算的，第二层下面的128map是由第一层下面的48map计算的；而第三层和第二层的虚线是完全交叉的，说明每一个192map都是由前面的128+128=256map同时计算得到的。</li>
</ul>
</li>
<li>具体的网络结构：<ul>
<li><img src="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_7/AlexNet_1.jpg" alt="网络结构"></li>
<li>这边有个LRN层/LRN处理(Local Response Normalization)，<img src="http://img.mp.itc.cn/upload/20170416/8ac1ca6800a7485194624beb95d1a12a.png" alt="LRN"><ul>
<li>N: 这一层的kernel总数</li>
<li>a<sup>i</sup><sub>(x,y)</sub>: kernel i 上的 (x,y) 位置参数</li>
<li>k, n, α, β, : 自行设置的参数</li>
<li>相当于把不同kernel的同一位置关联起来，<strong>对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。</strong></li>
<li>如下图，中间kernel红色位置为计算位置，LRN统计该红色位置对应的向左、向右的kernel对应位置的值（n值决定“计算”范围）<img src="http://img.mp.itc.cn/upload/20170416/60232c3551694c609ad71669dd2d1e98_th.png" alt="LRN可视化示意"></li>
</ul>
</li>
<li>使用了Relu激活函数，基于ReLU的深度卷积网络比基于tanh和sigmoid的网络训练快数倍（论文中有证明）</li>
<li>使用了dropout（只在网络的最后的两个全连接层有使用），但是在训练阶段和测试阶段设置不同<ul>
<li>在训练阶段：设置一个概率，以该概率随即屏蔽神经元（文章提到0.5，也就是在训练的时候每个神经元有50%的可能参与或不参与计算）。</li>
<li>在测试阶段：把0.5改为0，然后需要把结果*0.5，因为求和会是之前的两倍！建立一个假设—在有dropout的网络中，每次输出都是不同的，那么“mean network”产生的结果会比 ，单独几个独立的dropout的网络结果的mean融合会更好！或者理解为：几个网络输出的average，这是ensemble常用的手段！这里的意思是，dropout网络相当于把网络每一层都mean了，每一层都是ensemble，那么理论上这样可能会比直接结果ensemble会更好！（事实也是如此）</li>
</ul>
</li>
<li>数据扩充：1.图片平移或水平翻转 2.对RGB空间做PCA，然后对PAC做一个（0, 0.1）的高斯扰动，根据论文，就是对光照强度和颜色进行处理，保证网络不受光照强度和颜色变化的影响</li>
<li>重叠池化 (Overlapping Pooling)：步长s=2，窗口z=3；也就是池化输出特征过程中添加相邻像素的信息</li>
</ul>
</li>
<li>reference：<ul>
<li><a href="http://www.sohu.com/a/134347664_642762" target="_blank" rel="noopener">http://www.sohu.com/a/134347664_642762</a></li>
<li><a href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_segmentation.html" target="_blank" rel="noopener">https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_segmentation.html</a></li>
<li><a href="https://blog.csdn.net/yangdashi888/article/details/77918311" target="_blank" rel="noopener">https://blog.csdn.net/yangdashi888/article/details/77918311</a></li>
<li><a href="https://blog.csdn.net/github_36923418/article/details/93492299" target="_blank" rel="noopener">https://blog.csdn.net/github_36923418/article/details/93492299</a></li>
</ul>
</li>
</ul>
<h3 id="3-2-VGGNet深度神经网络出现"><a href="#3-2-VGGNet深度神经网络出现" class="headerlink" title="3.2 VGGNet深度神经网络出现"></a>3.2 VGGNet深度神经网络出现</h3><blockquote>
<p>Simonyan, Karen, and Andrew Zisserman. “Very deep convolutional networks for large-scale image recognition.” arXiv preprint arXiv:1409.1556 (2014).<br><a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1409.1556.pdf</a></p>
</blockquote>
<ul>
<li><a href="https://www.cnblogs.com/bigcindy/p/10688835.html" target="_blank" rel="noopener">中文翻译</a></li>
<li><a href="https://www.aiuai.cn/aifarm138.html" target="_blank" rel="noopener">一篇很棒的解释文章</a>【该篇文章原作者<a href="http://yuenshome.cn/" target="_blank" rel="noopener">Yuens’s blog</a>暂时无法接通】</li>
<li><a href="https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg16.py" target="_blank" rel="noopener">VGG16的keras实现代码</a></li>
<li><a href="https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg19.py" target="_blank" rel="noopener">VGG19的keras实现代码</a></li>
<li>论文中所采用的网络结构<img src="http://www-gageet-com-static.smartgslb.com/wp-content/uploads/2014/09/QQ%E6%88%AA%E5%9B%BE20140917104851.jpg" width="60%"></li>
<li>上图所用的网络的参数数量（单位:Million）<img src="http://www.gageet.com/wp-content/uploads/2014/09/QQ%E6%88%AA%E5%9B%BE20140917110908.jpg" width="60%"><ul>
<li>作者一共对比了六个网络的性能，上上图每一列代表一个网络，且从左至右网络逐渐加深（作者就是想对比不同的kernel尺寸和网络深度的影响），第二个网络的 LRN(Local Response Normalization) 在后续四个网络并没有用到，因为作者通过实验发现 LRN 在 ILSVRC dataset 上效果没有提升，反而增加了内存和时间消耗</li>
<li>VGGNet的发现<ul>
<li>LRN层无用增益（A和A-LRN）</li>
<li>一定条件下，随着网络深度的增加，分类性能提高</li>
<li>conv1x1的非线性变化有作用（C和D）</li>
<li>一定条件下，多个小的卷积核比同等视野的单个大的卷积核性能好（B）</li>
</ul>
</li>
<li>Localization问题：<ul>
<li>使用的VGG16</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="3-3-GoogLeNet"><a href="#3-3-GoogLeNet" class="headerlink" title="3.3 GoogLeNet"></a>3.3 GoogLeNet</h3><blockquote>
<p>Szegedy, Christian, et al. “Going deeper with convolutions.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015.<br><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf" target="_blank" rel="noopener">http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf</a></p>
</blockquote>
<ul>
<li><a href="https://www.jianshu.com/p/271a23f9ac5f" target="_blank" rel="noopener">中文翻译</a></li>
<li>GoogLeNet怎么出来的？或者说Inception怎么出来的？感觉是作者某天阅读了<a href="https://arxiv.org/abs/1310.6343" target="_blank" rel="noopener">Provable bounds for learning some deep representations</a>这篇论文，意识到传统的提高深度神经网络性能的方法（例如 扩大训练集 或 扩大网络规模）不得行<ul>
<li>小规模数据集容易使得网络过拟合，而高质量的大规模数据集又很难得到，例如区分 Siberian husky 和 Eskimo dog (论文中给的例子，其实是 西伯利亚哈士奇 和 爱斯基摩犬)</li>
<li>增加网络尺寸会导致计算资源的的显著增加</li>
</ul>
</li>
<li>解决这些问题的方法就是 “sparsely connected architectures” （显然缺点都是铺垫、铺垫~）。这个的理论基础就是 <a href="https://arxiv.org/abs/1310.6343" target="_blank" rel="noopener">Provable bounds for learning some deep representations</a> <blockquote>
<p>Their main result states that if the probability distribution of the data-set is representable by a large, very sparse deep neural network, then the optimal network topology can be constructed layer by layer by analyzing the correlation statistics of the activations of the last layer and clustering neurons with highly correlated outputs.<br>他们的主要成果说明如果数据集的概率分布可以通过一个大的、稀疏的深度神经网络表示，则最优的网络拓扑结构可以通过分析前一层激活的相关性统计和聚类高度相关的神经元来一层层的构建。</p>
<ul>
<li><strong>卷积自身便具有稀疏性</strong>，所以效果好。同时AlexNet之后的网络大家的网络几乎就都是统一的结构（一条直线从上到下），那么作者开始思考”是否可以使用滤波器水平的稀疏性”，此时作者又发现有一些论文发现 <strong>“对于稀疏矩阵乘法，将稀疏矩阵聚类为相对密集的子矩阵会有更佳的性能”</strong>，那么此时答案就很明显了 <strong>“卷积”，”聚类”</strong></li>
</ul>
</blockquote>
</li>
<li>所以就构建了<strong>初始版本的Inception模块</strong> <img src="/Deep-Learning-Study-Roadmap/Inception-module,naive-version.png" width="60%"></li>
<li>这里有个问题，<strong>参数爆炸</strong>，比如说Previous layer的输出为 28x28x192 ，如果使用96个 3x3convolutions，那么这里的参数就是 3x3x192x96+192(权重数量+偏置数量) (参考：<a href="https://blog.csdn.net/mynodex/article/details/101430452" target="_blank" rel="noopener">计算网络中的参数量(param)和浮点计算量(FLOPs)</a>)。如果后面每层都这样子的话参数超级大，所以最好缩减参数。问题根源是 Previous layer 的卷积层数量太多，但是肯定不能减少 Previous layer 的卷积层数量。可替代的方法是加 1x1convolutions 先减少卷积层数量（或者说降低前一层的维度,当然论文也提到了 1x1convolutions 里的rectified linear activation也有好处）。</li>
<li>以inception(3a) (GoogLeNet中的一个inception名称，见下下图) 为例计算一下缩减的参数数量<img src="/Deep-Learning-Study-Roadmap/googlenet-count.png" width="100%"></li>
<li>因而更新版的<strong>缩减参数的Inception模块</strong> <img src="/Deep-Learning-Study-Roadmap/inception-module-with-dimension-reductions.png" width="60%"></li>
<li>auxiliary classifiers:GoogLeNet网络仅计算带有参数的层时是22层(如果还计算池化层的话，则是27层)。直接训练容易出现梯度消失问题，因而加了两个auxiliary classifiers结构（图中的红色方框区域）。在训练过程中，auxiliary classifiers的损失以0.3的权重加到网络的整个损失上。在推断时，这些辅助网络被丢弃。<ul>
<li><img src="/Deep-Learning-Study-Roadmap/googlenet-architecture-image.png" width="100%"></li>
</ul>
</li>
<li><p>所以以下为完整版的GoogLeNet的网络结构（”＃3×3reduce”和”＃5×5reduce”表示在3×3和5×5卷积之前，使用的降维层中的1×1卷积的数量，”pool proj”表示3x3maxpooling之后，使用的1x1卷积数量）<img src="/Deep-Learning-Study-Roadmap/googlenet-architecture.png" width="100%"></p>
</li>
<li><p>reference:</p>
<ul>
<li><a href="https://www.aiuai.cn/aifarm138.html" target="_blank" rel="noopener">https://www.aiuai.cn/aifarm138.html</a></li>
<li><a href="http://www.gageet.com/2014/09178.php" target="_blank" rel="noopener">http://www.gageet.com/2014/09178.php</a></li>
<li><a href="https://www.jianshu.com/p/a2ad00eddbd5" target="_blank" rel="noopener">https://www.jianshu.com/p/a2ad00eddbd5</a></li>
<li><a href="https://www.jianshu.com/p/271a23f9ac5f" target="_blank" rel="noopener">https://www.jianshu.com/p/271a23f9ac5f</a></li>
<li><a href="https://blog.csdn.net/mynodex/article/details/101430452" target="_blank" rel="noopener">https://blog.csdn.net/mynodex/article/details/101430452</a></li>
</ul>
</li>
</ul>
<h3 id="3-4-ResNet极深度神经网络"><a href="#3-4-ResNet极深度神经网络" class="headerlink" title="3.4 ResNet极深度神经网络"></a>3.4 ResNet极深度神经网络</h3><blockquote>
<p>He, Kaiming, et al. “Deep residual learning for image recognition.” arXiv preprint arXiv:1512.03385 (2015).<br><a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1512.03385.pdf</a></p>
<p>从这一篇paper开始，我希望能够从一个易于接受的逻辑记录文献阅读，即：</p>
<ul>
<li>What’s the problem we need to solve?</li>
<li>What is the solution?</li>
<li>Why this solution works?</li>
</ul>
</blockquote>
<h4 id="what-problem"><a href="#what-problem" class="headerlink" title="what problem?"></a>what problem?</h4><ul>
<li>Deep is better 到底对不对<ul>
<li>如果考虑的是梯度消失/爆炸问题，论文说了这个问题几乎已经被”规范化初始化和中间归一化层(normalized initialization and intermediate normalization layers)”解决了</li>
<li>貌似问题解决了，但是测试一下，发现并非如此，而且该问题产生的原因还不是过拟合导致的（训练误差相对测试误差没有太大区别）<img src="https://pic2.zhimg.com/80/v2-dcf5688dad675cbe8fb8be243af5e1fd_hd.jpg" width="100%"></li>
<li>如果我们把浅层神经网络看成是深层神经网络的一个子集的话，那么最坏的结果是深层神经网络和浅层神经网络的效果一样（也就是其他部分非子集部分的作用只是简单的1-&gt;1映射），至少结果不会更差。这个结论和上图的结论并不一致，说明现有的神经网络结构并没有达到预期效果。<blockquote>
<p>Let us consider a shallower architecture and its deeper counterpart that adds more layers onto it. There exists a solution by construction to the deeper model: the added layers are identity mapping, and the other layers are copied from the learned shallower model.The existence of this constructed solution indicates that a deeper model should produce no higher training error than its shallower counterpart.</p>
</blockquote>
</li>
<li>那么我们的问题就成了：<strong>如何让深层神经网络有着不输浅层神经网络的性能呢？</strong></li>
</ul>
</li>
</ul>
<h4 id="What-is-the-solution"><a href="#What-is-the-solution" class="headerlink" title="What is the solution?"></a>What is the solution?</h4><ul>
<li><img src="/Deep-Learning-Study-Roadmap/residual learning.png" width="60%"></li>
<li>这里有一个问题，即如果跳层连接时维度不同不可以直接相加怎么办，三个方案：<ul>
<li>zero-padding shortcut（全0填充）来增加维度，所有的shortcut都没有参数</li>
<li>projection shortcuts来增加维度（维度不一致时使用），其他的shortcut都是identity（恒等映射）</li>
<li>所有的shortcut都使用projection shortcuts</li>
<li>备注：Identity shortcuts(直接进行同纬度的元素级相加)，论文还研究了Projection shortcuts()</li>
<li>$a=b+C$<h4 id="Why-this-solution-works"><a href="#Why-this-solution-works" class="headerlink" title="Why this solution works?"></a>Why this solution works?</h4></li>
</ul>
</li>
</ul>
<ul>
<li>reference:<ul>
<li><a href="https://zhuanlan.zhihu.com/p/31852747" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31852747</a></li>
<li><a href="https://blog.csdn.net/lanran2/article/details/79057994" target="_blank" rel="noopener">https://blog.csdn.net/lanran2/article/details/79057994</a></li>
<li><a href="https://blog.csdn.net/csdnldp/article/details/78313087" target="_blank" rel="noopener">https://blog.csdn.net/csdnldp/article/details/78313087</a></li>
<li><a href="https://blog.csdn.net/qq_25491201/article/details/78405549" target="_blank" rel="noopener">https://blog.csdn.net/qq_25491201/article/details/78405549</a></li>
</ul>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap" target="_blank" rel="noopener">https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap</a></li>
<li><a href="https://mp.weixin.qq.com/s/8cP3TIlE1IIzkawc69XOug" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/8cP3TIlE1IIzkawc69XOug</a></li>
</ol>

    </article>
    <!-- license  -->
    
        <div class="license-wrapper">
            <p>Author：<a href="https://fizzeryu.github.io">Changyu Li</a>
            <p>原文链接：<a href="https://fizzeryu.github.io/Deep-Learning-Study-Roadmap.html">https://fizzeryu.github.io/Deep-Learning-Study-Roadmap.html</a>
            <p>发表日期：<a href="https://fizzeryu.github.io/Deep-Learning-Study-Roadmap.html">February 1st 2020, 9:26:47 pm</a>
            <p>更新日期：<a href="https://fizzeryu.github.io/Deep-Learning-Study-Roadmap.html">February 7th 2020, 9:51:06 pm</a>
            <p>版权声明：本文采用<a rel="license noopener" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可</p>
        </div>
    
    <!-- paginator  -->
    <ul class="post-paginator">
        <li class="next">
            
                <div class="nextSlogan">Next Post</div>
                <a href= "/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95.html" title= "markdown常用语法">
                    <div class="nextTitle">markdown常用语法</div>
                </a>
            
        </li>
        <li class="previous">
            
                <div class="prevSlogan">Previous Post</div>
                <a href= "/hexo%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98.html" title= "hexo中遇到的问题">
                    <div class="prevTitle">hexo中遇到的问题</div>
                </a>
            
        </li>
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    
    <!-- partial('_partial/comment/changyan') -->
    <!--PC版-->


    
    

    <!-- 评论 -->
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
            
                <a href="mailto:changyulve@gmail.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="//github.com/FizzerYu" class="iconfont-archer github" target="_blank" title=github></a>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
            
                <a href="https://www.linkedin.com/in/%E9%95%BF%E5%AE%87-%E6%9D%8E-515a5a176/" class="iconfont-archer linkedin" target="_blank" title=linkedin></a>
            
        
    
        
    
        
    
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank">Archer</a></span>
    </div>
    <!-- 不蒜子  -->
    
    <div class="busuanzi-container">
    
     
    <span id="busuanzi_container_site_pv">PV: <span id="busuanzi_value_site_pv"></span> :)</span>
    
    </div>
    
</footer>
    </div>
    <!-- toc -->
    
    <div class="toc-wrapper" style=
    







top:50vh;

    >
        <div class="toc-catalog">
            <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
        </div>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Deep-Learning-Report"><span class="toc-number">1.</span> <span class="toc-text">1 Deep Learning Report</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-DBN"><span class="toc-number">2.</span> <span class="toc-text">2 DBN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-深度学习前夜的里程碑"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 深度学习前夜的里程碑</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-展示深度学习前景的里程碑"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 展示深度学习前景的里程碑</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-ImageNet革命（深度学习大爆炸）"><span class="toc-number">3.</span> <span class="toc-text">3 ImageNet革命（深度学习大爆炸）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-AlexNet的深度学习突破"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 AlexNet的深度学习突破</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-VGGNet深度神经网络出现"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 VGGNet深度神经网络出现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-GoogLeNet"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 GoogLeNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-ResNet极深度神经网络"><span class="toc-number">3.4.</span> <span class="toc-text">3.4 ResNet极深度神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#what-problem"><span class="toc-number">3.4.1.</span> <span class="toc-text">what problem?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#What-is-the-solution"><span class="toc-number">3.4.2.</span> <span class="toc-text">What is the solution?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Why-this-solution-works"><span class="toc-number">3.4.3.</span> <span class="toc-text">Why this solution works?</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">4.</span> <span class="toc-text">Reference</span></a></li></ol>
    </div>
    
    <div class="back-top iconfont-archer">&#xe639;</div>
    <div class="sidebar sidebar-hide">
    <ul class="sidebar-tabs sidebar-tabs-active-0">
        <li class="sidebar-tab-archives"><span class="iconfont-archer">&#xe67d;</span><span class="tab-name">Archive</span></li>
        <li class="sidebar-tab-tags"><span class="iconfont-archer">&#xe61b;</span><span class="tab-name">Tag</span></li>
        <li class="sidebar-tab-categories"><span class="iconfont-archer">&#xe666;</span><span class="tab-name">Cate</span></li>
    </ul>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-panel-archives">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-and-search">
        <div class="total-archive">
        Total : 6
        </div>
        <!-- search  -->
        
    </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2020 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/04</span><a class="archive-post-title" href= "/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95.html" >markdown常用语法</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/01</span><a class="archive-post-title" href= "/Deep-Learning-Study-Roadmap.html" >Deep Learning Study Roadmap</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/01</span><a class="archive-post-title" href= "/hexo%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98.html" >hexo中遇到的问题</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/26</span><a class="archive-post-title" href= "/Information-Century.html" >Information Century</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/22</span><a class="archive-post-title" href= "/A-scalable-pipeline-for-designing.html" >A scalable pipeline for designing</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/21</span><a class="archive-post-title" href= "/Hello-World.html" >Hello World</a>
        </li>
    
    </div>
  </div>
        <div class="sidebar-panel-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name" data-tags="Deep Learning"><span class="iconfont-archer">&#xe606;</span>Deep Learning</span>
    
        <span class="sidebar-tag-name" data-tags="论文阅读"><span class="iconfont-archer">&#xe606;</span>论文阅读</span>
    
        <span class="sidebar-tag-name" data-tags="hexo"><span class="iconfont-archer">&#xe606;</span>hexo</span>
    
        <span class="sidebar-tag-name" data-tags="synthetic biology"><span class="iconfont-archer">&#xe606;</span>synthetic biology</span>
    
    </div>
    <div class="iconfont-archer sidebar-tags-empty">&#xe678;</div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br/>
    1、请确保node版本大于6.2<br/>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br/>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br/>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
jsonContent:
  meta: false
  pages: false
  posts:
    title: true
    date: true
    path: true
    text: false
    raw: false
    content: false
    slug: false
    updated: false
    comments: false
    link: false
    permalink: false
    excerpt: false
    categories: true
    tags: true</pre>
    </div> 
    <div class="sidebar-tags-list"></div>
</div>
        <div class="sidebar-panel-categories">
    <div class="sidebar-categories-name">
    
    </div>
    <div class="iconfont-archer sidebar-categories-empty">&#xe678;</div>
    <div class="sidebar-categories-list"></div>
</div>
    </div>
</div> 
    <script>
    var siteMeta = {
        root: "/",
        author: "Changyu Li"
    }
</script>
    <!-- CDN failover -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
    <script type="text/javascript">
        if (typeof window.$ === 'undefined')
        {
            console.warn('jquery load from jsdelivr failed, will load local script')
            document.write('<script src="/lib/jquery.min.js">\x3C/script>')
        }
    </script>
    <script src="/scripts/main.js"></script>
    <!-- algolia -->
    
    <!-- busuanzi  -->
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    <!-- CNZZ  -->
    
    </div>
    <!-- async load share.js -->
    
        <script src="/scripts/share.js" async></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->    
     
    </body>
</html>


